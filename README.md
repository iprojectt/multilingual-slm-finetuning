# multilingual-slm-finetuning
Pretrained a 120M-parameter multilingual language model (English, Hindi, Awadhi) and fine-tuned it for text simplification and PII de-identification using LoRA-based parameter-efficient tuning.
